{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "KI24aUpqeVEY",
    "outputId": "12de48de-fc62-43a0-e0a0-521e5fc2a9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-vision in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-vision) (2.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-vision) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-vision) (4.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.25.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user1\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "#!pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J36K5LVbAZW1"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import pyautogui\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1: Google OCR -- detect text in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_text(path):\n",
    "#     \"\"\"Detects text in the file.\"\"\"\n",
    "#     from google.oauth2 import service_account\n",
    "#     from google.cloud import vision\n",
    "\n",
    "#     credentials = service_account.Credentials.from_service_account_file('divine-outlet-408519-ead34ab34a37.json')\n",
    "\n",
    "#     client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "#     with open(path, \"rb\") as image_file:\n",
    "#         content = image_file.read()\n",
    "\n",
    "#     image = vision.Image(content=content)\n",
    "\n",
    "#     response = client.text_detection(image=image)\n",
    "#     texts = response.text_annotations\n",
    "\n",
    "#     return([text.description for text in texts])\n",
    "\n",
    "\n",
    "#     if response.error.message:\n",
    "#         raise Exception(\n",
    "#             \"{}\\nFor more info on error messages, check: \"\n",
    "#             \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8yFbsetB_nUM"
   },
   "outputs": [],
   "source": [
    "# def strRecognition(list):\n",
    "#     # Extracting product names and quantities\n",
    "#   description_section = re.search(r'Description\\n(.*?)\\n(?:P\\.O\\. No\\.|Date)', list[0], re.DOTALL).group(1)\n",
    "#   product_info = re.findall(r'(\\d{1,4} [\\w\\s\\*,\\.]+) (\\d+)', description_section)\n",
    "\n",
    "#   products = []\n",
    "#   for quantity, name, _ in product_info:\n",
    "#       products.append({\n",
    "#           'Product': name.strip(),\n",
    "#           'Quantity': quantity.replace(',', '')\n",
    "#       })\n",
    "\n",
    "#   # Extracting rates\n",
    "#   rates_section = re.search(r'Date\\n[\\d/]+\\n([\\d\\s.$]+)\\nInvoice', str(list[0])).group(1)\n",
    "#   rates = re.findall(r'[\\d.]+', rates_section)\n",
    "\n",
    "#   # Assigning rates to products\n",
    "#   for i, rate in enumerate(rates):\n",
    "#       products[i]['Rate'] = rate\n",
    "\n",
    "#   # Printing extracted information\n",
    "#   for product in products:\n",
    "#       print(f\"Product: {product['Product']}, Quantity: {product['Quantity']}, Rate: {product['Rate']}\")\n",
    "\n",
    "#   # Creating a DataFrame\n",
    "#   df = pd.DataFrame(products)\n",
    "\n",
    "#   # Printing DataFrame\n",
    "#   return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2: Google OCR -- detect text in files\n",
    "\n",
    "This function is able to detect texts by blocks, which may be more suitable for this case with tables as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def async_detect_document(gcs_source_uri, gcs_destination_uri):\n",
    "#     \"\"\"OCR with PDF/TIFF as source files on GCS\"\"\"\n",
    "#     import json\n",
    "#     import re\n",
    "#     from google.cloud import vision\n",
    "#     from google.cloud import storage\n",
    "\n",
    "#     # Supported mime_types are: 'application/pdf' and 'image/tiff'\n",
    "#     mime_type = \"image/tiff\"\n",
    "\n",
    "#     # How many pages should be grouped into each json output file.\n",
    "#     batch_size = 1\n",
    "\n",
    "#     credentials = service_account.Credentials.from_service_account_file('credential/divine-outlet-408519-ead34ab34a37.json')\n",
    "#     client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "#     feature = vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "\n",
    "#     gcs_source = vision.GcsSource(uri=gcs_source_uri)\n",
    "#     input_config = vision.InputConfig(gcs_source=gcs_source, mime_type=mime_type)\n",
    "\n",
    "#     gcs_destination = vision.GcsDestination(uri=gcs_destination_uri)\n",
    "#     output_config = vision.OutputConfig(\n",
    "#         gcs_destination=gcs_destination, batch_size=batch_size\n",
    "#     )\n",
    "\n",
    "#     async_request = vision.AsyncAnnotateFileRequest(\n",
    "#         features=[feature], input_config=input_config, output_config=output_config\n",
    "#     )\n",
    "\n",
    "#     operation = client.async_batch_annotate_files(requests=[async_request])\n",
    "\n",
    "#     print(\"Waiting for the operation to finish.\")\n",
    "#     operation.result(timeout=420)\n",
    "\n",
    "#     # Once the request has completed and the output has been\n",
    "#     # written to GCS, we can list all the output files.\n",
    "#     storage_client = storage.Client()\n",
    "\n",
    "#     match = re.match(r\"gs://([^/]+)/(.+)\", gcs_destination_uri)\n",
    "#     bucket_name = match.group(1)\n",
    "#     prefix = match.group(2)\n",
    "\n",
    "#     bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "#     # List objects with the given prefix, filtering out folders.\n",
    "#     blob_list = [\n",
    "#         blob\n",
    "#         for blob in list(bucket.list_blobs(prefix=prefix))\n",
    "#         if not blob.name.endswith(\"/\")\n",
    "#     ]\n",
    "#     print(\"Output files:\")\n",
    "#     for blob in blob_list:\n",
    "#         print(blob.name)\n",
    "\n",
    "#     # Process the first output file from GCS.\n",
    "#     # Since we specified batch_size=2, the first response contains\n",
    "#     # the first two pages of the input file.\n",
    "#     output = blob_list[0]\n",
    "\n",
    "#     json_string = output.download_as_bytes().decode(\"utf-8\")\n",
    "#     response = json.loads(json_string)\n",
    "\n",
    "#     # The actual response for the first page of the input file.\n",
    "#     first_page_response = response[\"responses\"][0]\n",
    "#     annotation = first_page_response[\"fullTextAnnotation\"]\n",
    "\n",
    "#     # Here we print the full text from the first page.\n",
    "#     # The response contains more information:\n",
    "#     # annotation/pages/blocks/paragraphs/words/symbols\n",
    "#     # including confidence scores and bounding boxes\n",
    "#     print(\"Full text:\\n\")\n",
    "#     print(annotation[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 3: OCR Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocrSpaceFile(filename, api_key, overlay=False, language='eng', OCREngine = 2):\n",
    "\n",
    "    payload = {'isOverlayRequired': overlay,\n",
    "               'apikey': api_key,\n",
    "               'language': language,\n",
    "               'isTable': True,\n",
    "               'OCREngine': OCREngine,\n",
    "               #'detectOrientation':True\n",
    "               }\n",
    "    with open(filename, 'rb') as f:\n",
    "        r = requests.post('https://api.ocr.space/parse/image',\n",
    "                          files={filename: f},\n",
    "                          data=payload,\n",
    "                          )\n",
    "    return r.content.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract information from the converted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the result from API of best performance\n",
    "def parsedText(filename, language = 'eng', OCREngine =2 ):\n",
    "    response = ocrSpaceFile(filename, language = language,  OCREngine =OCREngine)\n",
    "    data = json.loads(response)\n",
    "    #there are two type of converting result of the OCR API\n",
    "    #one is putting the result in one string\n",
    "    text = data['ParsedResults'][0]['ParsedText']\n",
    "    #the other is writing them in separate lines\n",
    "    separateLines = []\n",
    "    for i in range(len(data['ParsedResults'][0]['TextOverlay']['Lines'])):\n",
    "\n",
    "        separateLines.append(data['ParsedResults'][0]['TextOverlay']['Lines'][i]['LineText'])\n",
    "    \n",
    "    return text, separateLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractString(text):\n",
    "    date=re.findall(r'\\d{1,2}/\\d{1,2}/\\d{4}',text)[0]\n",
    "    invoiceNo = re.findall('(?<![A-Z]{2}\\s)\\d{5,}', text)[0]\n",
    "    companyName = re.findall('(?!R&JY).+INC', text)[0]\n",
    "    \n",
    "    return date, invoiceNo, companyName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vendor Number is the initials of the company name, which is required when entering the invoice info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInitials(text):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Extract the first letter of each word and convert it to uppercase\n",
    "    initials = [word[0].upper() for word in words if word]\n",
    "    \n",
    "    # Join the first three initials\n",
    "    return ''.join(initials[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrate all these functions into one\n",
    "def readStrings(text):\n",
    "    date, invoiceNo, companyName = extractString(text)\n",
    "    companyInitial = extractInitials(companyName)\n",
    "    return date, invoiceNo, companyInitial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract item informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLines(text, marker_pattern):\n",
    "    # Search for the marker using the regex pattern\n",
    "    marker_match = re.search(marker_pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    # If the marker isn't found, return an empty list\n",
    "    if not marker_match:\n",
    "        return []\n",
    "\n",
    "    # Find the part of the text after the marker\n",
    "    text_after_marker = text[marker_match.end():]\n",
    "\n",
    "    # Split the text into lines\n",
    "    lines = text_after_marker.strip().split('\\n')\n",
    "\n",
    "    # Define a function to check if a line starts with a number\n",
    "    def starts_with_number(s):\n",
    "        return s.lstrip()[0].isdigit()\n",
    "\n",
    "    # Filter and return the lines that start with a number and contain 2 to 4 tabs\n",
    "    return [line for line in lines if starts_with_number(line) and 2 <= line.count('\\t')]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print the lines\n",
    "#if any words in the markers pattern is detected, identify that row as the header of the table\n",
    "def itemInfo(text, marker_pattern = r'(数量|quantity|摘要|description|重量|weight|rate)'):\n",
    "    \n",
    "    extracted_lines = extractLines(text, r'(数量|quantity|摘要|description|重量|weight|rate)')\n",
    "    amounts=[]\n",
    "    rates = []\n",
    "    items = []\n",
    "    for line in extracted_lines:\n",
    "                #amount is the first number in a row\n",
    "                #the thousands separator is \",\" ,but it may be recognized as a decimal point\n",
    "                amount_match = re.findall('\\d{0,3}[.,]?\\d+', line)[0] \n",
    "                #if nothing is fetched, return the line and let the user manually enter the amount\n",
    "                amount = amount_match[0] if amount_match else input(f\"Enter amount for line '{line}': \")\n",
    "                #rate is the second number on the invoice, it must contain a decimal separator\n",
    "                rate_match =re.findall(amount+'.*?(\\t\\d{0,3}[.,]{0,1}\\d+[\\.,]\\d+)', line)[0]\n",
    "                #if nothing is fetched, return the line and let the user manually enter the rate\n",
    "                rate = rate_match[0] if rate_match else input(f\"Enter rate for line '{line}': \")\n",
    "                rate = re.sub('[.,]','.', rate)\n",
    "                rate = rate.replace('\\t', '')\n",
    "                #item is the rest part in a row\n",
    "                item_match = re.findall(amount+'?(.*)'+rate, line)[0]\n",
    "                #if nothing is fetched, return the line and let the user manually enter the item\n",
    "                item = item_match[0].strip() if item_match else input(f\"Enter item for line '{line}': \")\n",
    "                item = re.findall(r'\\t{0,1}(.+?)\\t$', item)[0]\n",
    "                item = item.replace('\\t', ' ')\n",
    "                amount = re.sub('[.,]',',', amount)\n",
    "                amounts.append(amount)\n",
    "                rates.append(rate)\n",
    "                items.append(item)\n",
    "\n",
    "    df = pd.DataFrame({'amount':amounts,\n",
    "                          'item':items,\n",
    "                          'rate': rates})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add item code to the item information dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the matching rule\n",
    "#rule = pd.read_excel('data\\matchingRules\\InventorySummaryReport.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchingCode(item,rule):\n",
    "    score=np.repeat(0,len(rule))\n",
    "    for i in range(len(rule)):\n",
    "        score[i]=fuzz.ratio(item, rule['項目名稱_x000D_\\nItem Name'][i])\n",
    "        idxMax=np.argmax(np.array(score))\n",
    "    return rule['項目編號_x000D_\\nItem No.'][idxMax], rule['項目名稱_x000D_\\nItem Name'][idxMax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function combines all the functions together\n",
    "def readFile(filename,language = 'cht', OCREngine =2):\n",
    "    text, separateLines = parsedText(filename, language = language, OCREngine =OCREngine)\n",
    "    date,invoiceNo, companyName=readStrings(text)\n",
    "    df=itemInfo(text)\n",
    "    df['code'] = df['item'].apply(lambda x: matchingCode(x, rule)[0])\n",
    "    df['matched_rule'] = df['item'].apply(lambda x: matchingCode(x, rule)[1])\n",
    "    \n",
    "    return date,invoiceNo, companyName, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
